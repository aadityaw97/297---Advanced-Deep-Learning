{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_knowledge_distillation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uttMZkKeJhNr"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgpf7ZtJgTz",
        "outputId": "6213f9c0-08dd-4f0c-b5a3-5647f21ee85e"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "tf.random.set_seed(666)\r\n",
        "# Load the FashionMNIST dataset, scale the pixel values\r\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\r\n",
        "X_train = X_train/255.\r\n",
        "X_test = X_test/255.\r\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\r\n",
        "# Change the pixel values to float32 and reshape input data\r\n",
        "X_train = X_train.astype(\"float32\").reshape(-1, 28, 28, 1)\r\n",
        "X_test = X_test.astype(\"float32\").reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euvm9RIzM-d3"
      },
      "source": [
        "Teacher model shallow convNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3A028WyM_8D"
      },
      "source": [
        "def get_teacher_model():\r\n",
        "    model = models.Sequential()\r\n",
        "    model.add(layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)))\r\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(layers.Conv2D(32, (5, 5), activation=\"relu\"))\r\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(layers.Dropout(0.2))\r\n",
        "    model.add(layers.Flatten())\r\n",
        "    model.add(layers.Dense(128, activation=\"relu\"))\r\n",
        "    model.add(layers.Dense(10))\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxIGJBgnN82S"
      },
      "source": [
        "Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eXFjwHeN1sx"
      },
      "source": [
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0t7yM6vOAWZ"
      },
      "source": [
        "Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUAdbhUrOFOw"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100).batch(64)\r\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li21uh3pOIP1"
      },
      "source": [
        "Train teacher model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puJEY0zVOLqE",
        "outputId": "9021f108-4bc5-4129-e6f3-828e15926b36"
      },
      "source": [
        "teacher_model = get_teacher_model()\r\n",
        "teacher_model.compile(loss=loss_func, optimizer=optimizer, metrics=[\"accuracy\"])\r\n",
        "teacher_model.fit(train_ds,\r\n",
        "                  validation_data=test_ds,\r\n",
        "                  epochs=10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 33s 34ms/step - loss: 0.8046 - accuracy: 0.7149 - val_loss: 0.4348 - val_accuracy: 0.8405\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.4004 - accuracy: 0.8552 - val_loss: 0.3855 - val_accuracy: 0.8535\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.3407 - accuracy: 0.8746 - val_loss: 0.3385 - val_accuracy: 0.8752\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.3079 - accuracy: 0.8869 - val_loss: 0.3327 - val_accuracy: 0.8788\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2911 - accuracy: 0.8934 - val_loss: 0.3067 - val_accuracy: 0.8884\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2715 - accuracy: 0.8987 - val_loss: 0.2920 - val_accuracy: 0.8922\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2546 - accuracy: 0.9040 - val_loss: 0.2748 - val_accuracy: 0.8993\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2426 - accuracy: 0.9085 - val_loss: 0.2803 - val_accuracy: 0.8969\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2342 - accuracy: 0.9110 - val_loss: 0.2710 - val_accuracy: 0.8994\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.2229 - accuracy: 0.9144 - val_loss: 0.2682 - val_accuracy: 0.9044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f493af846d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmRHqAm0OPqy"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f71sRAyORTM",
        "outputId": "065764ef-a91a-4164-ed33-e87285c82e50"
      },
      "source": [
        "print(\"Test accuracy: {:.2f}\".format(teacher_model.evaluate(test_ds)[1]*100))\r\n",
        "#save model\r\n",
        "teacher_model.save_weights(\"teacher_model.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 10ms/step - loss: 0.2682 - accuracy: 0.9044\n",
            "Test accuracy: 90.44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z2yS4HcOpJ_"
      },
      "source": [
        "Student model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta9ZRp1qOrhp"
      },
      "source": [
        "def get_student_model():\r\n",
        "    model = models.Sequential()\r\n",
        "    model.add(layers.Input(shape=(28, 28, 1)))\r\n",
        "    model.add(layers.Flatten())\r\n",
        "    model.add(layers.Dense(48, activation=\"relu\"))\r\n",
        "    model.add(layers.Dense(10))\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "def get_kd_loss(student_logits, teacher_logits, temperature=0.5):\r\n",
        "    teacher_probs = tf.nn.softmax(teacher_logits / temperature)\r\n",
        "    kd_loss = tf.compat.v1.losses.softmax_cross_entropy(\r\n",
        "        teacher_probs, student_logits / temperature, temperature**2)\r\n",
        "    return kd_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYcRdA_aOvZO"
      },
      "source": [
        "Optimize student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGJEa6k_OxKm"
      },
      "source": [
        "student_model = get_student_model()\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\r\n",
        "# Average the loss across the batch size within an epoch\r\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\r\n",
        "valid_loss = tf.keras.metrics.Mean(name=\"test_loss\")\r\n",
        "# Specify the performance metric\r\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_acc\")\r\n",
        "valid_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"valid_acc\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo-EKpEoPEV6"
      },
      "source": [
        "Train student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FO_-9HhPGLz"
      },
      "source": [
        "@tf.function\r\n",
        "def model_train(images, labels, teacher_model, \r\n",
        "                student_model, optimizer, temperature):\r\n",
        "    teacher_logits = teacher_model(images)\r\n",
        "\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        student_logits = student_model(images)\r\n",
        "        loss = get_kd_loss(student_logits, teacher_logits, temperature)\r\n",
        "    \r\n",
        "    gradients = tape.gradient(loss, student_model.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(gradients, student_model.trainable_variables))\r\n",
        "\r\n",
        "    train_loss(loss)\r\n",
        "    train_acc(labels, tf.nn.softmax(student_logits))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yLQJxkEPI_E"
      },
      "source": [
        "Validate student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTru7XgrPLSQ"
      },
      "source": [
        "@tf.function\r\n",
        "def model_validate(images, labels, teacher_model, \r\n",
        "                   student_model, temperature):\r\n",
        "    teacher_logits = teacher_model(images)\r\n",
        "\r\n",
        "    student_logits = student_model(images)\r\n",
        "    loss = get_kd_loss(student_logits, teacher_logits, temperature)\r\n",
        "\r\n",
        "    valid_loss(loss)\r\n",
        "    valid_acc(labels, tf.nn.softmax(student_logits))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl1YquR6PSm_"
      },
      "source": [
        "Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR5TZ_VATsAj"
      },
      "source": [
        "def train_model(epochs, teacher_model, student_model, optimizer, temp=0.5):\r\n",
        "    for epoch in range(epochs):\r\n",
        "        for (images, labels) in train_ds:\r\n",
        "            model_train(images, labels, teacher_model, student_model, optimizer, temp)\r\n",
        "\r\n",
        "        for (images, labels) in test_ds:\r\n",
        "            model_validate(images, labels, teacher_model, student_model, temp)\r\n",
        "            \r\n",
        "        (loss, acc) = train_loss.result(), train_acc.result()\r\n",
        "        (val_loss, val_acc) = valid_loss.result(), valid_acc.result()\r\n",
        "        \r\n",
        "        train_loss.reset_states(), train_acc.reset_states()\r\n",
        "        valid_loss.reset_states(), valid_acc.reset_states()\r\n",
        "        \r\n",
        "        template = \"Epoch {}, loss: {:.3f}, acc: {:.3f}, val_loss: {:.3f}, val_acc: {:.3f}\"\r\n",
        "        print (template.format(epoch+1,\r\n",
        "                            loss,\r\n",
        "                            acc,\r\n",
        "                            val_loss,\r\n",
        "                            val_acc))\r\n",
        "        \r\n",
        "    \r\n",
        "    return teacher_model, student_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQDBaT40T8zu",
        "outputId": "903cf9d5-44c2-44cb-d921-102546180b7d"
      },
      "source": [
        "_, student_model = train_model(10, teacher_model, student_model, optimizer)\r\n",
        "student_model.save_weights(\"student_model.h5\")\r\n",
        "!ls -lh *.h5\r\n",
        "teacher_model.summary()\r\n",
        "student_model.summary()\r\n",
        "def representative_data_gen():\r\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\r\n",
        "        yield [input_value]\r\n",
        "def convert_to_tflite(model, tflite_file):\r\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
        "    converter.representative_dataset = representative_data_gen\r\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n",
        "    converter.inference_input_type = tf.int8\r\n",
        "    converter.inference_output_type = tf.int8\r\n",
        "    tflite_quant_model = converter.convert()\r\n",
        "    open(tflite_file, 'wb').write(tflite_quant_model)\r\n",
        "convert_to_tflite(teacher_model, \"teacher.tflite\")\r\n",
        "convert_to_tflite(student_model, \"student.tflite\")\r\n",
        "!ls -lh *.tflite"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, loss: 0.113, acc: 0.820, val_loss: 0.101, val_acc: 0.827\n",
            "Epoch 2, loss: 0.089, acc: 0.849, val_loss: 0.088, val_acc: 0.843\n",
            "Epoch 3, loss: 0.083, acc: 0.859, val_loss: 0.097, val_acc: 0.833\n",
            "Epoch 4, loss: 0.082, acc: 0.859, val_loss: 0.096, val_acc: 0.837\n",
            "Epoch 5, loss: 0.080, acc: 0.863, val_loss: 0.089, val_acc: 0.844\n",
            "Epoch 6, loss: 0.077, acc: 0.867, val_loss: 0.094, val_acc: 0.841\n",
            "Epoch 7, loss: 0.076, acc: 0.867, val_loss: 0.092, val_acc: 0.849\n",
            "Epoch 8, loss: 0.076, acc: 0.869, val_loss: 0.088, val_acc: 0.848\n",
            "Epoch 9, loss: 0.074, acc: 0.870, val_loss: 0.093, val_acc: 0.845\n",
            "Epoch 10, loss: 0.073, acc: 0.873, val_loss: 0.083, val_acc: 0.857\n",
            "-rw-r--r-- 1 root root 163K Dec 18 14:54 student_model.h5\n",
            "-rw-r--r-- 1 root root 335K Dec 18 14:50 teacher_model.h5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 16)        416       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 32)          12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 80,202\n",
            "Trainable params: 80,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 48)                37680     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                490       \n",
            "=================================================================\n",
            "Total params: 38,170\n",
            "Trainable params: 38,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpa9j2o4jv/assets\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpd9bt_0k6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpd9bt_0k6/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 40K Dec 18 14:54 student.tflite\n",
            "-rw-r--r-- 1 root root 84K Dec 18 14:54 teacher.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}