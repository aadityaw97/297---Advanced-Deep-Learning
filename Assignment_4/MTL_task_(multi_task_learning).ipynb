{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTL task (multi task learning).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ee6586e696d4ad4a4b14e7627b3c86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b167913a085a48118cab6c534ae4c9fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b850774d8f3a4a84b142b182cf061e6a",
              "IPY_MODEL_d715bf8c3cde4fd4ab95eeb0137594c4"
            ]
          }
        },
        "b167913a085a48118cab6c534ae4c9fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b850774d8f3a4a84b142b182cf061e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_562a673b84b840b6bd83bf13ccfa6023",
            "_dom_classes": [],
            "description": "Epoch:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b449beaa37d94c28aee1e042f1e2019a"
          }
        },
        "d715bf8c3cde4fd4ab95eeb0137594c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c940b6bce534f3a8c5ded35f8baca89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91d7885a8de54c37b38211bc62078c2a"
          }
        },
        "562a673b84b840b6bd83bf13ccfa6023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b449beaa37d94c28aee1e042f1e2019a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c940b6bce534f3a8c5ded35f8baca89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91d7885a8de54c37b38211bc62078c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34d3787b3aee4b5a8d542a1d6969676e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5691201e2b84c788119a08e2facc250",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06eee720bfea45f69265063da18c476b",
              "IPY_MODEL_c70abc0b64d749d0b10b5bc40b1d59c4"
            ]
          }
        },
        "f5691201e2b84c788119a08e2facc250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06eee720bfea45f69265063da18c476b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4185ab9b3b740cd88beeb0a92aa6ec6",
            "_dom_classes": [],
            "description": "Iteration:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 181,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74b5582350eb4b2e99d93bff2d7cb39f"
          }
        },
        "c70abc0b64d749d0b10b5bc40b1d59c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3fd8cef90bc4f9b92ed63b3eb1fb92e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/181 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8934d98c4c5411ba6a7ded253b06138"
          }
        },
        "e4185ab9b3b740cd88beeb0a92aa6ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74b5582350eb4b2e99d93bff2d7cb39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3fd8cef90bc4f9b92ed63b3eb1fb92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8934d98c4c5411ba6a7ded253b06138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FVX-VBvBdLB"
      },
      "source": [
        "Install dependecies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2zgN3SkbO6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ece222-8a7b-4edd-8cdd-7f00adf97c00"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/nlp\r\n",
        "!pip install transformers==2.11.0\r\n",
        "!pip install nlp==0.2.0\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import transformers\r\n",
        "import nlp\r\n",
        "import logging\r\n",
        "logging.basicConfig(level=logging.INFO)\r\n",
        "import dataclasses\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from transformers.training_args import is_tpu_available\r\n",
        "from transformers.trainer import get_tpu_sampler\r\n",
        "from transformers.data.data_collator import DataCollator, InputDataClass\r\n",
        "from torch.utils.data.distributed import DistributedSampler\r\n",
        "from torch.utils.data.sampler import RandomSampler\r\n",
        "from typing import List, Union, Dict"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/nlp\n",
            "  Cloning https://github.com/huggingface/nlp to /tmp/pip-req-build-yx2c5azc\n",
            "  Running command git clone -q https://github.com/huggingface/nlp /tmp/pip-req-build-yx2c5azc\n",
            "Requirement already satisfied (use --upgrade to upgrade): datasets==1.1.3 from git+https://github.com/huggingface/nlp in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (1.19.4)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (2.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (0.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (4.41.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (2.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (0.70.11.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from datasets==1.1.3) (0.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets==1.1.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets==1.1.3) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.1.3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.1.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.1.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.1.3) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.1.3) (1.15.0)\n",
            "Building wheels for collected packages: datasets\n",
            "  Building wheel for datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datasets: filename=datasets-1.1.3-cp36-none-any.whl size=158234 sha256=07b4e9264f6dac88ea025eb1d27340621869eeb2130d505b401e9643adcc9b25\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xg3psyx_/wheels/ec/83/70/1320deb5c8c3b17b432b2a896067946c05dd5e8b1c32b91731\n",
            "Successfully built datasets\n",
            "Requirement already satisfied: transformers==2.11.0 in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.1.94)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.12.5)\n",
            "Requirement already satisfied: nlp==0.2.0 in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (0.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (1.19.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (3.0.12)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (3.0.4)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMv397SBBsvP"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vs9zw5yB0Un",
        "outputId": "cb2ccbc0-2645-4438-d8e3-b81e7310384a"
      },
      "source": [
        "dataset_dict = {\"stsb\": nlp.load_dataset('glue', name=\"stsb\"),  \"rte\": nlp.load_dataset('glue', name=\"rte\"),\"commonsense_qa\": nlp.load_dataset('commonsense_qa'),}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py for additional imports.\n",
            "INFO:filelock:Lock 140277665846944 acquired on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.json\n",
            "INFO:filelock:Lock 140277665846944 released on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0\n",
            "INFO:nlp.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/stsb/1.0.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/glue/stsb/1.0.0\n",
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py for additional imports.\n",
            "INFO:filelock:Lock 140277280824568 acquired on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.json\n",
            "INFO:filelock:Lock 140277280824568 released on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/rte/1.0.0\n",
            "INFO:nlp.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/glue/rte/1.0.0\n",
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py for additional imports.\n",
            "INFO:filelock:Lock 140277316876328 acquired on /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/commonsense_qa.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/commonsense_qa.json\n",
            "INFO:filelock:Lock 140277316876328 released on /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py.lock\n",
            "WARNING:nlp.builder:Using custom data configuration default\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0\n",
            "INFO:nlp.builder:Reusing dataset commonsense_qa (/root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4TKRSfCDv0"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR2_VRSoCFr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebbc4d3-9462-440f-d636-57eff7f0b4e9"
      },
      "source": [
        "class MultitaskModel(transformers.PreTrainedModel):\r\n",
        "    def __init__(self, encoder, taskmodels_dict):        \r\n",
        "        super().__init__(transformers.PretrainedConfig())\r\n",
        "\r\n",
        "        self.encoder = encoder\r\n",
        "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def create(cls, model_name, model_type_dict, model_config_dict):\r\n",
        "        shared_encoder = None\r\n",
        "        taskmodels_dict = {}\r\n",
        "        for task_name, model_type in model_type_dict.items():\r\n",
        "            model = model_type.from_pretrained(\r\n",
        "                model_name, \r\n",
        "                config=model_config_dict[task_name],\r\n",
        "            )\r\n",
        "            if shared_encoder is None:\r\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\r\n",
        "            else:\r\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\r\n",
        "            taskmodels_dict[task_name] = model\r\n",
        "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def get_encoder_attr_name(cls, model):\r\n",
        "        \"\"\"\r\n",
        "        The encoder transformer is named differently in each model \"architecture\".\r\n",
        "        This method lets us get the name of the encoder attribute\r\n",
        "        \"\"\"\r\n",
        "        model_class_name = model.__class__.__name__\r\n",
        "        if model_class_name.startswith(\"Bert\"):\r\n",
        "            return \"bert\"\r\n",
        "        elif model_class_name.startswith(\"Roberta\"):\r\n",
        "            return \"roberta\"\r\n",
        "        elif model_class_name.startswith(\"Albert\"):\r\n",
        "            return \"albert\"\r\n",
        "        else:\r\n",
        "            raise KeyError(f\"Add support for new model {model_class_name}\")\r\n",
        "\r\n",
        "    def forward(self, task_name, **kwargs):\r\n",
        "        return self.taskmodels_dict[task_name](**kwargs)\r\n",
        "\r\n",
        "model_type_dict={\"stsb\": transformers.AutoModelForSequenceClassification,\r\n",
        "        \"rte\": transformers.AutoModelForSequenceClassification,\r\n",
        "        \"commonsense_qa\": transformers.AutoModelForMultipleChoice,}\r\n",
        "model_config_dict={\"stsb\": transformers.AutoConfig.from_pretrained(\"roberta-base\", num_labels=1),\r\n",
        "        \"rte\": transformers.AutoConfig.from_pretrained(\"roberta-base\", num_labels=2),\r\n",
        "        \"commonsense_qa\": transformers.AutoConfig.from_pretrained(\"roberta-base\"),}\r\n",
        "\r\n",
        "multitask_model = MultitaskModel.create(\r\n",
        "    model_name=\"roberta-base\",\r\n",
        "    model_type_dict=model_type_dict,\r\n",
        "    model_config_dict=model_config_dict,\r\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForMultipleChoice not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGiCjq6PCVPF"
      },
      "source": [
        "Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjt6Sq8jCZ_l",
        "outputId": "fb29d064-8c2e-4e34-b17b-9a5ba62b65ef"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"roberta-base\")\r\n",
        "\r\n",
        "def convert_to_stsb_features(example_batch):\r\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\r\n",
        "    features = tokenizer.batch_encode_plus(\r\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\r\n",
        "    )\r\n",
        "    features[\"labels\"] = example_batch[\"label\"]\r\n",
        "    return features\r\n",
        "\r\n",
        "def convert_to_rte_features(example_batch):\r\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\r\n",
        "    features = tokenizer.batch_encode_plus(\r\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\r\n",
        "    )\r\n",
        "    features[\"labels\"] = example_batch[\"label\"]\r\n",
        "    return features\r\n",
        "\r\n",
        "def convert_to_commonsense_qa_features(example_batch):\r\n",
        "    num_examples = len(example_batch[\"question\"])\r\n",
        "    num_choices = len(example_batch[\"choices\"][0][\"text\"])\r\n",
        "    features = {}\r\n",
        "    for example_i in range(num_examples):\r\n",
        "        choices_inputs = tokenizer.batch_encode_plus(\r\n",
        "            list(zip(\r\n",
        "                [example_batch[\"question\"][example_i]] * num_choices,\r\n",
        "                example_batch[\"choices\"][example_i][\"text\"],\r\n",
        "            )),\r\n",
        "            max_length=max_length, pad_to_max_length=True,\r\n",
        "        )\r\n",
        "        for k, v in choices_inputs.items():\r\n",
        "            if k not in features:\r\n",
        "                features[k] = []\r\n",
        "            features[k].append(v)\r\n",
        "    labels2id = {char: i for i, char in enumerate(\"ABCDE\")}\r\n",
        "    # Dummy answers for test\r\n",
        "    if example_batch[\"answerKey\"][0]:\r\n",
        "        features[\"labels\"] = [labels2id[ans] for ans in example_batch[\"answerKey\"]]\r\n",
        "    else:\r\n",
        "        features[\"labels\"] = [0] * num_examples    \r\n",
        "    return features\r\n",
        "\r\n",
        "\r\n",
        "max_length = 128\r\n",
        "convert_func_dict = {\"stsb\": convert_to_stsb_features,\r\n",
        "    \"rte\": convert_to_rte_features,\r\n",
        "    \"commonsense_qa\": convert_to_commonsense_qa_features,}\r\n",
        "\r\n",
        "columns_dict = {\"stsb\": ['input_ids', 'attention_mask', 'labels'],\r\n",
        "    \"rte\": ['input_ids', 'attention_mask', 'labels'],\r\n",
        "    \"commonsense_qa\": ['input_ids', 'attention_mask', 'labels'],}\r\n",
        "\r\n",
        "features_dict = {}\r\n",
        "for task, dataset in dataset_dict.items():\r\n",
        "    features_dict[task] = {}\r\n",
        "    for phase, phase_dataset in dataset.items():\r\n",
        "        features_dict[task][phase] = phase_dataset.map(\r\n",
        "            convert_func_dict[task],\r\n",
        "            batched=True,\r\n",
        "            load_from_cache_file=False,\r\n",
        "        )\r\n",
        "        print(task, phase, len(phase_dataset), len(features_dict[task][phase]))\r\n",
        "        features_dict[task][phase].set_format(type=\"torch\", columns=columns_dict[task],)\r\n",
        "        print(task, phase, len(phase_dataset), len(features_dict[task][phase]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-d2b0e2b1e353f1b9fbe0725471db143f.arrow\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.18it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 5749 examples in 12666815 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-d2b0e2b1e353f1b9fbe0725471db143f.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-aec11a0dac2eda110e765a5c78c608aa.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb train 5749 5749\n",
            "stsb train 5749 5749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.01it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1500 examples in 3324096 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-aec11a0dac2eda110e765a5c78c608aa.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-593c638955a8714e57a2c4867a2ef077.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb validation 1500 1500\n",
            "stsb validation 1500 1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.43it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1379 examples in 3027294 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-593c638955a8714e57a2c4867a2ef077.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-38be6965ba491702cf4515ce3bf905d2.arrow\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb test 1379 1379\n",
            "stsb test 1379 1379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 2490 examples in 5996688 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-38be6965ba491702cf4515ce3bf905d2.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-24ce8344dcbe3bd232bdc5bc71e48d3b.arrow\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.70it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 277 examples in 663580 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-24ce8344dcbe3bd232bdc5bc71e48d3b.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-fb596d2fec55c5205924eefa5c903826.arrow\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rte train 2490 2490\n",
            "rte train 2490 2490\n",
            "rte validation 277 277\n",
            "rte validation 277 277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.99it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 3000 examples in 7178101 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-fb596d2fec55c5205924eefa5c903826.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-b7200320d1603b178797c3e10a70c72a.arrow\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rte test 3000 3000\n",
            "rte test 3000 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.03it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 9741 examples in 102030077 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-b7200320d1603b178797c3e10a70c72a.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-55713c9b25e6141f0385d7a21a89818a.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa train 9741 9741\n",
            "commonsense_qa train 9741 9741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.65it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1221 examples in 12786529 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-55713c9b25e6141f0385d7a21a89818a.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-e40d5adaeb67d334a4bdad765d7f911e.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa validation 1221 1221\n",
            "commonsense_qa validation 1221 1221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.76it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1140 examples in 11940278 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-e40d5adaeb67d334a4bdad765d7f911e.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa test 1140 1140\n",
            "commonsense_qa test 1140 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48w1GHkaCp3t"
      },
      "source": [
        "DataCollator and MultiTask Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVngmt1hCwPg"
      },
      "source": [
        "class NLPDataCollator(DataCollator):\r\n",
        "\r\n",
        "    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\r\n",
        "        first = features[0]\r\n",
        "        if isinstance(first, dict):\r\n",
        "          if \"labels\" in first and first[\"labels\"] is not None:\r\n",
        "              if first[\"labels\"].dtype == torch.int64:\r\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\r\n",
        "              else:\r\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\r\n",
        "              batch = {\"labels\": labels}\r\n",
        "          for k, v in first.items():\r\n",
        "              if k != \"labels\" and v is not None and not isinstance(v, str):\r\n",
        "                  batch[k] = torch.stack([f[k] for f in features])\r\n",
        "          return batch\r\n",
        "        else:          \r\n",
        "          return DefaultDataCollator().collate_batch(features)\r\n",
        "\r\n",
        "\r\n",
        "class StrIgnoreDevice(str):\r\n",
        "  \r\n",
        "    def to(self, device):\r\n",
        "        return self\r\n",
        "\r\n",
        "\r\n",
        "class DataLoaderWithTaskname:\r\n",
        "    def __init__(self, task_name, data_loader):\r\n",
        "        self.task_name = task_name\r\n",
        "        self.data_loader = data_loader\r\n",
        "\r\n",
        "        self.batch_size = data_loader.batch_size\r\n",
        "        self.dataset = data_loader.dataset\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data_loader)\r\n",
        "    \r\n",
        "    def __iter__(self):\r\n",
        "        for batch in self.data_loader:\r\n",
        "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\r\n",
        "            yield batch\r\n",
        "\r\n",
        "\r\n",
        "class MultitaskDataloader:\r\n",
        "    def __init__(self, dataloader_dict):\r\n",
        "        self.dataloader_dict = dataloader_dict\r\n",
        "        self.num_batches_dict = {\r\n",
        "            task_name: len(dataloader) \r\n",
        "            for task_name, dataloader in self.dataloader_dict.items()\r\n",
        "        }\r\n",
        "        self.task_name_list = list(self.dataloader_dict)\r\n",
        "        self.dataset = [None] * sum(\r\n",
        "            len(dataloader.dataset) \r\n",
        "            for dataloader in self.dataloader_dict.values()\r\n",
        "        )\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return sum(self.num_batches_dict.values())\r\n",
        "\r\n",
        "    def __iter__(self):      \r\n",
        "        task_choice_list = []\r\n",
        "        for i, task_name in enumerate(self.task_name_list):\r\n",
        "            task_choice_list += [i] * self.num_batches_dict[task_name]\r\n",
        "        task_choice_list = np.array(task_choice_list)\r\n",
        "        np.random.shuffle(task_choice_list)\r\n",
        "        dataloader_iter_dict = {\r\n",
        "            task_name: iter(dataloader) \r\n",
        "            for task_name, dataloader in self.dataloader_dict.items()\r\n",
        "        }\r\n",
        "        for task_choice in task_choice_list:\r\n",
        "            task_name = self.task_name_list[task_choice]\r\n",
        "            yield next(dataloader_iter_dict[task_name])    \r\n",
        "\r\n",
        "class MultitaskTrainer(transformers.Trainer):\r\n",
        "\r\n",
        "    def get_single_train_dataloader(self, task_name, train_dataset):\r\n",
        "        if self.train_dataset is None:\r\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\r\n",
        "        if is_tpu_available():\r\n",
        "            train_sampler = get_tpu_sampler(train_dataset)\r\n",
        "        else:\r\n",
        "            train_sampler = (\r\n",
        "                RandomSampler(train_dataset)\r\n",
        "                if self.args.local_rank == -1\r\n",
        "                else DistributedSampler(train_dataset)\r\n",
        "            )\r\n",
        "\r\n",
        "        data_loader = DataLoaderWithTaskname(\r\n",
        "            task_name=task_name,\r\n",
        "            data_loader=DataLoader(\r\n",
        "              train_dataset,\r\n",
        "              batch_size=self.args.train_batch_size,\r\n",
        "              sampler=train_sampler,\r\n",
        "              collate_fn=self.data_collator.collate_batch,\r\n",
        "            ),\r\n",
        "        )\r\n",
        "\r\n",
        "        if is_tpu_available():\r\n",
        "            data_loader = pl.ParallelLoader(\r\n",
        "                data_loader, [self.args.device]\r\n",
        "            ).per_device_loader(self.args.device)\r\n",
        "        return data_loader\r\n",
        "\r\n",
        "    def get_train_dataloader(self):\r\n",
        "        return MultitaskDataloader({task_name: self.get_single_train_dataloader(task_name, task_dataset)\r\n",
        "            for task_name, task_dataset in self.train_dataset.items()})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaE91uyC0dK"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Gjc9sRC17y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "2ee6586e696d4ad4a4b14e7627b3c86c",
            "b167913a085a48118cab6c534ae4c9fd",
            "b850774d8f3a4a84b142b182cf061e6a",
            "d715bf8c3cde4fd4ab95eeb0137594c4",
            "562a673b84b840b6bd83bf13ccfa6023",
            "b449beaa37d94c28aee1e042f1e2019a",
            "8c940b6bce534f3a8c5ded35f8baca89",
            "91d7885a8de54c37b38211bc62078c2a",
            "34d3787b3aee4b5a8d542a1d6969676e",
            "f5691201e2b84c788119a08e2facc250",
            "06eee720bfea45f69265063da18c476b",
            "c70abc0b64d749d0b10b5bc40b1d59c4",
            "e4185ab9b3b740cd88beeb0a92aa6ec6",
            "74b5582350eb4b2e99d93bff2d7cb39f",
            "b3fd8cef90bc4f9b92ed63b3eb1fb92e",
            "f8934d98c4c5411ba6a7ded253b06138"
          ]
        },
        "outputId": "3b9895f1-0799-41ab-e14b-fa48bab6bf0a"
      },
      "source": [
        "train_dataset = {task_name: dataset[\"train\"] \r\n",
        "    for task_name, dataset in features_dict.items()}\r\n",
        "\r\n",
        "trainer = MultitaskTrainer(model=multitask_model,\r\n",
        "    args=transformers.TrainingArguments(\r\n",
        "        output_dir=\"./models/multitask_model\",\r\n",
        "        overwrite_output_dir=True, learning_rate=1e-5, do_train=True,\r\n",
        "        num_train_epochs=1, per_device_train_batch_size=100,  save_steps=3000, ),\r\n",
        "        data_collator=NLPDataCollator(),\r\n",
        "        train_dataset=train_dataset,)\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.training_args:PyTorch: setting up devices\n",
            "INFO:transformers.trainer:You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
            "INFO:transformers.trainer:***** Running training *****\n",
            "INFO:transformers.trainer:  Num examples = 17980\n",
            "INFO:transformers.trainer:  Num Epochs = 1\n",
            "INFO:transformers.trainer:  Instantaneous batch size per device = 100\n",
            "INFO:transformers.trainer:  Total train batch size (w. parallel, distributed & accumulation) = 100\n",
            "INFO:transformers.trainer:  Gradient Accumulation steps = 1\n",
            "INFO:transformers.trainer:  Total optimization steps = 181\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ee6586e696d4ad4a4b14e7627b3c86c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34d3787b3aee4b5a8d542a1d6969676e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=181.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UljOdqKC8_x"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nojJA-9gC_VA"
      },
      "source": [
        "preds_dict = {}\r\n",
        "for task_name in [\"rte\", \"stsb\", \"commonsense_qa\"]:\r\n",
        "    eval_dataloader = DataLoaderWithTaskname(\r\n",
        "        task_name, trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\r\n",
        "    )\r\n",
        "    print(eval_dataloader.data_loader.collate_fn)\r\n",
        "    preds_dict[task_name] = trainer._prediction_loop( eval_dataloader, \r\n",
        "        description=f\"Validation: {task_name}\",)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiRrSl_FDDgk"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo3X8vb1DFMR"
      },
      "source": [
        "nlp.load_metric('glue', name=\"rte\").compute(\r\n",
        "    np.argmax(preds_dict[\"rte\"].predictions, axis=1),\r\n",
        "    preds_dict[\"rte\"].label_ids,)\r\n",
        "\r\n",
        "nlp.load_metric('glue', name=\"stsb\").compute(preds_dict[\"stsb\"].predictions.flatten(),\r\n",
        "    preds_dict[\"stsb\"].label_ids,)\r\n",
        "\r\n",
        "\r\n",
        "np.mean(\r\n",
        "    np.argmax(preds_dict[\"commonsense_qa\"].predictions, axis=1)\r\n",
        "    == preds_dict[\"commonsense_qa\"].label_ids\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}